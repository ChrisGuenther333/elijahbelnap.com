<p>When I was in elementary school, I used to page through picture books of images from NASA Mars rovers. I was fascinated with the idea of exploration of Mars, and even more so that the task was being done remotely through robots. Fast forward a couple of decades, and I was able to connect my childhood fascination with Mars exploration with my more recent interest in machine learning.</p>

<p>The <a href="https://science.nasa.gov/mission/mars-reconnaissance-orbiter/science-instruments/">HiRise project</a> takes high-definition images of Mars’ surface for use in scientific research. NASA published a labeled dataset of some of these images. This data set has already been cleaned and augmented for machine learning, so it’s a great data set to use for practicing machine learning concepts.</p>

<p>In this post, I share my experience working with these HiRise images using neural networks. I’ll give an overview of my project, including some code snippets, before explaining my key takeaways from the experience. Spoiler alert: the project didn’t go quite as I imagined. I didn’t produce a useful algorithm, however, the process itself was valuable in introducing me to neural networks against a real data set. You can find all of my code and the necessary documentation to replicate my process <a href="https://github.com/elbel13/HiRISE-image-labeling">on Github</a>.</p>

<h2 id="why-i-did-this-project">Why I Did This Project</h2>

<p>To finish up my bacherlor’s degree, I had to perform a Capstone project. The idea was to demonstrate the skills acquired throughout the degree in a real-world scenario. I could have done a simple data analysis, however the overachiever in me acted up and wanted to do something new. So I set out to find a machine learning project that would stretch my current skills as well as force me to do new things. It turned out to be quite a bumpy ride and the project ultimately didn’t satisfy my original goals, but I did learn a lot. In the end, the capstone project helped me meet my degree requirement, which was the most important thing anyway.</p>

<p>With that in mind, bear with me as I’m not going to pretend to be a subject matter expert in this arena. I’m not going to pretend that I knew what I was doing the whole time, nor that my solution was ideal. As I mentioned earlier, I actually failed my original objectives. However, I think this was a great introduction to image classification and neural models for me and hopefully, it can be for others as well.</p>

<h2 id="an-overview-of-nueral-networks">An Overview of Nueral networks</h2>

<p>Neural networks are made up of different nodes, referred to as neurons, that each take inputs and produce outputs. I’m not going to go into depth on the mathematical side of what makes a neural network tick, as I don’t pretend to completely understand it myself, but to summarize neurons use a mathematical function to process inputs. Standford has an in-depth tutorial in which they go through the mathematical details, and you can read more <a href="http://deeplearning.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/">here</a> if you’re interested. The illustration below is from Standford’s article and is a simple representation of a single neuron in a neural network.</p>

<p><img src="/assets/images/single-neuron.png" alt="Single Neuron Algorithm Diagram" /></p>

<p>The above illustration shows various inputs into a single neuron and the output after the neuron applies its activation function. To form a multilevel neural network, multiple layers of neurons are strung together; the output of one layer becomes the input to the next layer. These layers are referred to as “hidden layers” within a model. The bellow diagram (also from Standford’s article) shows the first layer of inputs into the first hidden layer (L<sub>2</sub>), then the output of this layer being fed to the next hidden layer as input, which feeds into the final hidden layer that produces the final output.</p>

<p><img src="/assets/images/neural-network.png" alt="Multi-layered Nueral Network Diagram" /></p>

<p>Like other machine learning algorithms, these may be trained on large data sets to solve complex problems. During training, the network’s output for each gets evaluated against known “correct” outputs. The network’s function weights are then systematically adjusted based on this evaluation. The adjustment allows the network to improve its performance as training continues.</p>

<p>If you’d like to read more about the implementation details of neural networks, you can review the Standford article. If, like me, you need something that doesn’t go too far into depth on the mathematical details, I’d recommend <a href="https://en.wikipedia.org/wiki/Multilayer_perceptron#:~:text=A%20multilayer%20perceptron%20(MLP)%20is,that%20is%20not%20linearly%20separable.">Wikipidia’s article on Multilayer perception</a>.</p>

<h2 id="code-implementation">Code Implementation</h2>

<p>I used <a href="https://github.com/elbel13/HiRISE-image-labeling/tree/main/notebooks">Jupyter Notebooks</a> to store and document my code. The idea was for each notebook to show a different step of the process, which started with <a href="https://github.com/elbel13/HiRISE-image-labeling/blob/main/notebooks/DataWrangling.ipynb">preparing the data</a> and ended with an evaluation of the <a href="https://github.com/elbel13/HiRISE-image-labeling/blob/main/notebooks/Final_Model_Evaluation.ipynb">final model</a>. However, the majority of my notebooks focused on different training exercises to build a satisfactory model. During each training notebook, I tried tuning the values of one or more model parameters, evaluated the impact on the model, then incorporated the parameters that performed best into a model for further tuning in the next exercise.</p>

<p>Creating and running these notebooks took me about a month. The training exercises in particular were time consuming, as they were computationally intensive and took anywhere from 5 to 15 hours to run on my test server. For this reason, if you wish to repeat any parts of my process I would recomend at least 12 cores and 32 GB of RAM on your test system. My system was running two <a href="https://www.intel.com/content/www/us/en/products/sku/75790/intel-xeon-processor-e52630-v2-15m-cache-2-60-ghz/specifications.html">Intel Xeon E5-2630 v2</a> processors (12 total cores), 64 GB of RAM.</p>

<p>I’ll give an overview of some key parts of the code implementation before touching on my findings. The code snippets can not be run without first <a href="https://github.com/elbel13/HiRISE-image-labeling/tree/main">downloading the dataset</a> and running my <a href="https://github.com/elbel13/HiRISE-image-labeling/blob/main/notebooks/DataWrangling.ipynb">“Data Wrangling”</a> notebook to prepare the data, but after doing that you should be able to follow along with the post.</p>

<h3 id="libraries-used">Libraries Used</h3>

<p>I primarily used <a href="https://keras.io/">Keras</a> for this project, which is designed to make working with <a href="https://www.tensorflow.org/">Tensorflow</a> easier. Tensorflow is ideal for working with multidimensional arrays, or tensors. In my case, image data is represented well by tensors. Using Keras makes working with Tensorflow much more intuitive.</p>

<p>I occasionally used helper functions from <a href="https://github.com/elbel13/HiRISE-image-labeling/blob/main/notebooks/file_helpers.py">a module I wrote</a> for facilitating working with files, which relied on the <a href="https://dill.readthedocs.io/en/latest/">dill library</a> for serialization/deserialization of Python objects. This was primarily used to pass objects between notebooks for reuse.</p>

<p>The imports below will allow you to follow along with the other code snippet examples. However, you’ll also want to be sure to install all these libraries. The easiest way to do so may be to clone my <a href="https://github.com/elbel13/HiRISE-image-labeling">GitHub project</a> and <a href="https://github.com/elbel13/HiRISE-image-labeling?tab=readme-ov-file#create-anoconda-environment">set up an Anoconda environment</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="n">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="n">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="n">file_helpers</span> <span class="kn">import</span> <span class="n">unpickle_from_file</span>
</code></pre></div></div>

<h3 id="read-the-data">Read the Data</h3>

<p>If you follow my <a href="https://github.com/elbel13/HiRISE-image-labeling/tree/main">download instructions</a> and run the <a href="https://github.com/elbel13/HiRISE-image-labeling/blob/main/notebooks/DataWrangling.ipynb">Data Wrangling notebook</a> , all the data related files will be organized in the <code class="language-plaintext highlighter-rouge">data</code> directory. The <code class="language-plaintext highlighter-rouge">/data/processed_data</code> directory contains all the processed data we’ll need, while the ` training_images` subdirectory contains a subset of images for training. First we’ll load a list of the assigned image labels, then we’ll load the images themselves.</p>

<p>The llist of labels is a Python list that’s been serialized using dill. We saved this serialization to <code class="language-plaintext highlighter-rouge">test_labels_sorted.bin</code> in the Data Wrangling noteobook. The <code class="language-plaintext highlighter-rouge">unpickle_from_file</code> from my <code class="language-plaintext highlighter-rouge">file_helpers</code> module fascilitates the desirialization. Let’s deserialize the list into the <code class="language-plaintext highlighter-rouge">labels</code> variable.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Import the labels for the test data set for validation purposes
</span><span class="n">labels</span> <span class="o">=</span> <span class="nf">unpickle_from_file</span><span class="p">(</span><span class="sh">'</span><span class="s">../data/processed_data/test_labels_sorted.bin</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<p>Once we have the labels, we’re ready to load the images themselves. The <a href="https://tensorflow.org/api_docs/python/tf/keras/preThere%20are%20multiple%20different%20files%20here,%20corresponding%20to%20the%20diffeprocessing/image_dataset_from_directory">image_dataset_from_directory</a> method creates a <a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset">TensorFlow Dataset</a> object from a directory path. This object doesn’t necessarily load all the images into memory immediately, but rather serves as an abstraction of the data set that streams things into memory as needed. This greately fascilitates working with large data sets. However, we’ll adjust settings to prefer keeping as much of the data as we can in memory as possible.</p>

<p>In addition to the directory of our data set, <code class="language-plaintext highlighter-rouge">image_dataset_from_directory</code> takes several parameters to build out the Dataset. The <code class="language-plaintext highlighter-rouge">validation_split</code> parameter is how much of our data we plan to use for validation and how much we’ll want to train the model on. In our case we’re choosing to set aside 15% of the data set for validation. The <code class="language-plaintext highlighter-rouge">subset</code> parameter is used to tell the method whether to load this data set is the training portion or the validation portion of the data set. The <code class="language-plaintext highlighter-rouge">seed</code> is the seed to use for psudo random functions, and I’ve chosen <code class="language-plaintext highlighter-rouge">123</code> as a seed to maintain consistency between subsequent runs. The <code class="language-plaintext highlighter-rouge">image_size</code> is the image demensions of each image. The <code class="language-plaintext highlighter-rouge">batch_size</code> tells the model how many images to process per batch, and adjusting this parameter will affect both the processing speed and the way the model classifies the data.</p>

<p>The last parameter, <code class="language-plaintext highlighter-rouge">labels</code>, is the known labels assigned to each image. This argument expects an ordered Python list. The list should be ordered alphanumerically based on the image’s file name, as this will allow each image to be matched to the correct label.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Read training data
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">75</span>
<span class="n">img_height</span> <span class="o">=</span> <span class="mi">227</span>
<span class="n">img_width</span> <span class="o">=</span> <span class="mi">227</span>

<span class="n">train_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">image_dataset_from_directory</span><span class="p">(</span>
  <span class="sh">'</span><span class="s">../data/processed_data/training_images</span><span class="sh">'</span><span class="p">,</span>
  <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
  <span class="n">subset</span><span class="o">=</span><span class="sh">"</span><span class="s">training</span><span class="sh">"</span><span class="p">,</span>
  <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
  <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">),</span>
  <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
 <span class="n">labels</span> <span class="o">=</span> <span class="n">train_labels_sorted</span><span class="p">)</span>

<span class="c1">#Read validation data
</span><span class="n">val_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">image_dataset_from_directory</span><span class="p">(</span>
  <span class="sh">'</span><span class="s">../data/processed_data/training_images</span><span class="sh">'</span><span class="p">,</span>
  <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
  <span class="n">subset</span><span class="o">=</span><span class="sh">"</span><span class="s">validation</span><span class="sh">"</span><span class="p">,</span>
  <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
  <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">),</span>
  <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
 <span class="n">labels</span> <span class="o">=</span> <span class="n">train_labels_sorted</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="build-the-model">Build the Model</h3>

<p>Keras greatly simplifies building a TensorFlow model. One way it can do this is by allowing us to build the model in layers. Each layer contains a different step of the workflow, and the output of one layer is the input for the following one. Each layer may have a different function in the process.</p>

<p>The first layer in this model uses the rescaling method to convert input images to grayscale. The next layer (Conv2D) applies a convolusion matrix to filter the image down to essential features alysis (you can read more about how this layer works <a href="https://sourestdeeds.github.io/blog/convolution-and-relu/">here</a>). The MaxPooling2D further simplifies the image and reduces its demensions.</p>

<p>Following these layers, I’ve added a dropout layer. Neural networks tend to overfit data, so adding a dropout randomly discards some results to allow it to generalize better. This may seem counterintuitive at first, but a dropout layer placed between hidden layers can often make a model more versatile. I recomend this <a href="https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/">Dropout Regularization in Deep Learning Models with Keras</a> article to learn more on the topic.</p>

<p>Flatten comes next in the model, which as the name implies flattens the demensions of the input vectors. This prepares them to be passed to several Dense layers. The Dense layers define different neural layers in our network. In this case, we’re using layers of 256 neurons, except for the last layer that is using only one neuron for each classification class. That is because the shape of the final output will have an output prediction for each class.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">img_height</span> <span class="o">=</span> <span class="mi">227</span>
<span class="n">mg_width</span> <span class="o">=</span> <span class="mi">227</span>

<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">8</span>

<span class="n">model_layers</span> <span class="o">=</span> <span class="p">[</span>
	<span class="n">layers</span><span class="p">.</span><span class="nc">Rescaling</span><span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
	<span class="n">layers</span><span class="p">.</span><span class="nc">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">),</span>
	<span class="n">layers</span><span class="p">.</span><span class="nc">MaxPooling2D</span><span class="p">(),</span>
	<span class="n">layers</span><span class="p">.</span><span class="nc">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">),</span>
	<span class="n">layers</span><span class="p">.</span><span class="nc">MaxPooling2D</span><span class="p">(),</span>
	<span class="n">layers</span><span class="p">.</span><span class="nc">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">),</span>
	<span class="n">layers</span><span class="p">.</span><span class="nc">MaxPooling2D</span><span class="p">(),</span>
	<span class="n">layers</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
	<span class="n">layers</span><span class="p">.</span><span class="nc">Flatten</span><span class="p">(),</span>
	<span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">),</span>
	<span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">),</span>
	<span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">),</span>
	<span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)]</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">Sequential</span><span class="p">(</span><span class="n">model_layers</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">),</span>
		<span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="nc">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
		<span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">])</span>
</code></pre></div></div>

<h3 id="train-the-model">Train the Model</h3>

<p>After we’ve defined our model, we’re ready to train it. Training consists of having the model pass the training data through each layer in batches. On each pass, the model will learn the characteristics of the data. This will allow the model to make accurate predictions on similar data sets.</p>

<p>Even though the code is pretty simple, this is the most intensive part of the process. You can adjust the number of epochs to determine how many passes through the training data the model makes. After each pass, the model will take what it has learned up to this point and make predictions against the validation data set. The predictions are evaluated against the set’s actual labels to produce an accuracy score for the individual training epoch. While going through training exercises, it’s often helpful to plot these scores to determine the ideal number of epochs to train for as well as evaluate the model’s performance using different parameters.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">epochs</span><span class="o">=</span> <span class="mi">5</span>

<span class="c1">#Silence debug messages for cleaner output
</span><span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="sh">'</span><span class="s">TF_CPP_MIN_LOG_LEVEL</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">2</span><span class="sh">'</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span>
  <span class="n">train_ds</span><span class="p">,</span>
  <span class="n">validation_data</span> <span class="o">=</span> <span class="n">val_ds</span><span class="p">,</span>
  <span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span>
<span class="p">)</span>
</code></pre></div></div>

<h3 id="evaluate-performance">Evaluate Performance</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Read testing data
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">75</span>
<span class="n">img_height</span> <span class="o">=</span> <span class="mi">227</span>
<span class="n">img_width</span> <span class="o">=</span> <span class="mi">227</span>

<span class="n">test_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">image_dataset_from_directory</span><span class="p">(</span>
  <span class="sh">'</span><span class="s">../data/processed_data/testing_images</span><span class="sh">'</span><span class="p">,</span>
  <span class="n">seed</span> <span class="o">=</span> <span class="mi">123</span><span class="p">,</span>
  <span class="n">image_size</span><span class="o">=</span> <span class="p">(</span><span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">),</span>
  <span class="n">batch_size</span><span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">)</span>

<span class="c1">#Evaluate model
</span><span class="n">model_performance</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">test_ds</span><span class="p">,</span> <span class="n">return_dict</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">The model achieved </span><span class="sh">'</span><span class="p">,</span> <span class="n">model_performance</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">],</span> <span class="sh">'</span><span class="s"> accuracy on the test data set.</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">The model achieved </span><span class="sh">'</span><span class="p">,</span> <span class="n">model_performance</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">],</span> <span class="sh">'</span><span class="s"> loss on the test set.</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="results">Results</h2>

<p><img src="/assets/images/hirise-learning-curve.png" alt="Algortihm Learning Curve" /></p>

<h2 id="what-went-wrong">What Went Wrong?</h2>

<p><img src="/assets/images/hirise-labeled-image-examples.png" alt="Example Images With Actual VS Predicted Labels" /></p>
